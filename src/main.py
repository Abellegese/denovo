import orbax
from flax.training import orbax_utils
from model import CPCModel
import numpy as np
import yaml
from layers import Encoder
import orbax
import jax
import torch
import json
from utils import *



PATH = 'configs/base.yaml'
def _config(path):
    with open(path, "r") as conf:
        config = yaml.safe_load(conf)
    return config

# Reading the config
CONFIG = _config(PATH)
def _count_params(params): return sum(p.size for p in jax.tree_leaves(params))

def _build_encoder(config):
    model = Encoder(
        residues=config["residues"],
        dim_model=config["dim_model"],
        n_head=config["n_head"],
        dim_feedforward=config["dim_feedforward"],
        n_layers=config["n_layers"],
        dropout=config["dropout"],
        max_length=config["max_length"],
        max_charge=config["max_charge"],
        use_depthcharge=config["use_depthcharge"],
        dec_precursor_sos=config["dec_precursor_sos"],
    )
    return model
encoder = _build_encoder(CONFIG)
def load_and_use_encoder(checkpoint_path, spectra, precursor=None, spectr_mask=None):
  """Loads a CPCModel from a checkpoint, uses its encoder, and returns latent representations.

  Args:
      checkpoint_path: Path to the checkpoint file containing the saved model state.
      spectra: Input spectra data for the encoder.
      precurs: Precursor data (optional, depending on your model).
      spectr_mask: Spectrum mask (optional, depending on your model).

  Returns:
      A tuple containing the latent representations (z, c) generated by the encoder.
  """

  # Load the model state from the checkpoint
  state = _load_model(checkpoint_path)
  # Extract model parameters from the loaded state
  params = state['model']['params']
  print(_count_params(params))
  # Create a CPCModel instance
  model = CPCModel(
    input_dim = 768,
    hidden_dim = 166,
    output_dim = 166,
    encoders=encoder,
    batch_size=32,
    regressor=True # Replace with your encoder model(s)
  )

  # Initialize the model with loaded parameters
  z, c = model.apply(params, spectra, precursor, spectr_mask, method=model.get_latent_representations)

  # Use the encoder function to get latent representations
#   z, c = model.get_latent_representations(spectra, precursor, spectr_mask)

  return z, c

def _load_model(path):
  """Loads a previously saved Flax model state from the given path.

  Args:
      path: The file path where the model checkpoint is stored.

  Returns:
      A Flax TrainState object containing the loaded model parameters and optimizer state.
  """
  orbax_checkpointer = orbax.checkpoint.PyTreeCheckpointer()

  raw_restored = orbax_checkpointer.restore(path)

  return raw_restored


checkpoint_path = "/home/abellegese/Videos/pipeline/artifacts"
spectra = torch.ones((14, 165, 2)) # Your input spectra data
precursor = torch.ones((14, 3))
spectr_mask = torch.ones((14, 200))
# Prepare precurs and spectr_mask if your model requires them

z, c = load_and_use_encoder(checkpoint_path, spectra, precursor, spectr_mask)

